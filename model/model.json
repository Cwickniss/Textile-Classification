{
    "networkName": "Textile-Classification",
    "networkSettings": null,
    "networkMeta": {
        "openStatistics": false,
        "openTest": null,
        "zoom": 1,
        "netMode": "edit",
        "coreStatus": {},
        "chartsRequest": {
            "timerID": 851,
            "waitGlobalEvent": true,
            "doRequest": 3299,
            "showCharts": 3294
        }
    },
    "networkRootFolder": "",
    "networkElementList": {
        "1564399775664": {
            "layerId": "1564399775664",
            "layerName": "Data_1",
            "layerType": "Data",
            "layerSettings": {
                "Type": "Data",
                "testInfoIsInput": true,
                "accessProperties": {
                    "Columns": [],
                    "Dataset_size": "",
                    "Category": "Local",
                    "Type": "Data",
                    "Sources": [
                        {
                            "type": "file",
                            "path": "/home/tango/perceptilabs/textile/X.npy"
                        }
                    ],
                    "PathFake": [],
                    "Partition_list": [
                        [
                            70,
                            20,
                            10
                        ]
                    ],
                    "Shuffle_data": true,
                    "Action_space": ""
                }
            },
            "layerCode": {
                "Output": "class DataData_Data_1(DataSupervised):\n    \"\"\"Class responsible for loading data from files (e.g., numpy, csv, etc).\"\"\"    \n    def __init__(self):\n        self._variables = {}\n        self._columns = []\n        self._stored_sample = None\n\n        columns = {}\n        trn_sz_tot, val_sz_tot, tst_sz_tot = 0, 0, 0        \n        trn_gens_args_DataData_Data_1, val_gens_args_DataData_Data_1, tst_gens_args_DataData_Data_1 = [], [], []        \n\n        columns_DataData_Data_1_0 = None\n\n        global matrix_DataData_Data_1_0\n        matrix_DataData_Data_1_0 = np.load(\"/home/tango/perceptilabs/textile/X.npy\", mmap_mode='r+').astype(np.float32)\n        size_DataData_Data_1_0 = len(matrix_DataData_Data_1_0)\n        def generator_DataData_Data_1_0(idx_lo, idx_hi):\n            global matrix_DataData_Data_1_0\n            yield from matrix_DataData_Data_1_0[idx_lo:idx_hi]\n\n\n        if columns_DataData_Data_1_0 is not None:\n            columns[\"DataData_Data_1_0\"] = columns_DataData_Data_1_0\n            self._columns = columns_DataData_Data_1_0\n\n        trn_sz = int(round(0.01*70*size_DataData_Data_1_0))\n        val_sz = int(round(0.01*20*size_DataData_Data_1_0))\n        tst_sz = int(size_DataData_Data_1_0 - trn_sz - val_sz)\n\n        trn_sz_tot += trn_sz\n        val_sz_tot += val_sz\n        tst_sz_tot += tst_sz\n        \n        trn_gens_args_DataData_Data_1.append((generator_DataData_Data_1_0, 0, trn_sz))\n        val_gens_args_DataData_Data_1.append((generator_DataData_Data_1_0, trn_sz, trn_sz+val_sz))\n        tst_gens_args_DataData_Data_1.append((generator_DataData_Data_1_0, trn_sz+val_sz, trn_sz+val_sz+tst_sz))\n                    \n        self._trn_gens_args = trn_gens_args_DataData_Data_1\n        self._val_gens_args = val_gens_args_DataData_Data_1                                        \n        self._tst_gens_args = tst_gens_args_DataData_Data_1\n                    \n        self._trn_sz_tot = trn_sz_tot\n        self._val_sz_tot = val_sz_tot\n        self._tst_sz_tot = tst_sz_tot\n\n        self._variables = {k: v for k, v in locals().items() if can_serialize(v)}\n\n    @property\n    def variables(self) -> Dict[str, Picklable]:\n        \"\"\"Returns any variables that the layer should make available and that can be pickled.\"\"\"\n        return self._variables\n\n    @property\n    def sample(self) -> np.ndarray:\n        \"\"\"Returns a single data sample\"\"\"\n        if self._stored_sample is None:                    \n            self._stored_sample = next(self.make_generator_training())\n\n        return self._stored_sample\n\n    @property\n    def columns(self) -> List[str]:\n        \"\"\"Column names. Corresponds to each column in a sample \"\"\"\n        return self._columns.copy()\n\n    @property\n    def size_training(self) -> int:\n        \"\"\"Returns the size of the training dataset\"\"\"                    \n        return self._trn_sz_tot\n\n    @property\n    def size_validation(self) -> int:\n        \"\"\"Returns the size of the validation dataset\"\"\"\n        return self._val_sz_tot\n\n    @property\n    def size_testing(self) -> int:\n        \"\"\"Returns the size of the testing dataset\"\"\"                    \n        return self._tst_sz_tot\n                    \n    def make_generator_training(self) -> Generator[np.ndarray, None, None]:\n        \"\"\"Returns a generator yielding single samples of training data.\"\"\"                                        \n        def gen():\n            for fn, lo, hi in self._trn_gens_args:\n                for x in fn(lo, hi):\n                    self._output = x\n                    yield x\n        return gen()\n        \n    def make_generator_validation(self) -> Generator[np.ndarray, None, None]:\n        \"\"\"Returns a generator yielding single samples of validation data.\"\"\"                    \n        def gen():\n            for fn, lo, hi in self._val_gens_args:\n                for x in fn(lo, hi):\n                    self._output = x\n                    yield x\n        return gen()\n\n    def make_generator_testing(self) -> Generator[np.ndarray, None, None]:\n        \"\"\"Returns a generator yielding single samples of testing data.\"\"\"                            \n        def gen():\n            for fn, lo, hi in self._tst_gens_args:\n                for x in fn(lo, hi):\n                    self._output = x\n                    yield x\n        return gen()\n"
            },
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": true,
                "position": {
                    "top": 160,
                    "left": 200
                },
                "OutputDim": "64x64x1",
                "InputDim": "[]",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DataData",
            "connectionOut": [
                "1596824132180"
            ],
            "connectionIn": [],
            "connectionArrow": [
                "1596824132180"
            ],
            "layerSettingsTabName": "Code"
        },
        "1564399786876": {
            "layerId": "1564399786876",
            "layerName": "Data_2",
            "layerType": "Data",
            "layerSettings": {
                "Type": "Data",
                "testInfoIsInput": true,
                "accessProperties": {
                    "Columns": [],
                    "Dataset_size": "",
                    "Category": "Local",
                    "Type": "Data",
                    "Sources": [
                        {
                            "type": "file",
                            "path": "/home/tango/perceptilabs/textile/Y.npy"
                        }
                    ],
                    "PathFake": [],
                    "Partition_list": [
                        [
                            70,
                            20,
                            10
                        ]
                    ],
                    "Shuffle_data": true,
                    "Action_space": ""
                }
            },
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 340,
                    "left": 200
                },
                "OutputDim": "1",
                "InputDim": "[]",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DataData",
            "connectionOut": [
                "1596824119748"
            ],
            "connectionIn": [],
            "connectionArrow": [
                "1596824119748"
            ],
            "layerSettingsTabName": "Computer"
        },
        "1596824119748": {
            "layerId": "1596824119748",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "OneHot_1",
            "layerType": "Other",
            "layerSettings": {
                "N_class": "6"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 340,
                    "left": 310
                },
                "OutputDim": "6",
                "InputDim": "[1]",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "ProcessOneHot",
            "connectionOut": [
                "1596824310982"
            ],
            "connectionIn": [
                "1564399786876"
            ],
            "connectionArrow": [
                "1596824310982"
            ]
        },
        "1596824132180": {
            "layerId": "1596824132180",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_1",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "2",
                "Padding": "SAME",
                "Feature_maps": "64",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 160,
                    "left": 310
                },
                "OutputDim": "32x32x64",
                "InputDim": "[64, 64, 1]",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596825463589",
                "1596825483525"
            ],
            "connectionIn": [
                "1564399775664"
            ],
            "connectionArrow": [
                "1596825463589",
                "1596825483525"
            ]
        },
        "1596824172196": {
            "layerId": "1596824172196",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_2",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "2",
                "Padding": "SAME",
                "Feature_maps": "128",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 160,
                    "left": 490
                },
                "OutputDim": "16x16x128",
                "InputDim": "[32, 32, 128]",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596825573649",
                "1596825586247"
            ],
            "connectionIn": [
                "1596825483525"
            ],
            "connectionArrow": [
                "1596825573649",
                "1596825586247"
            ]
        },
        "1596824199078": {
            "layerId": "1596824199078",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_3",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "2",
                "Padding": "SAME",
                "Feature_maps": "256",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 160,
                    "left": 680
                },
                "OutputDim": "8x8x256",
                "InputDim": "[16, 16, 256]",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596825603293",
                "1596825646014"
            ],
            "connectionIn": [
                "1596825586247"
            ],
            "connectionArrow": [
                "1596825603293",
                "1596825646014"
            ]
        },
        "1596824298894": {
            "layerId": "1596824298894",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Fully Connected_1",
            "layerType": "Other",
            "layerSettings": {
                "Neurons": "6",
                "Activation_function": "Softmax",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 200,
                    "left": 970
                },
                "OutputDim": "6",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningFC",
            "connectionOut": [
                "1596824310982"
            ],
            "connectionIn": [
                "1596825658495"
            ],
            "connectionArrow": [
                "1596824310982"
            ]
        },
        "1596824310982": {
            "layerId": "1596824310982",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Normal_1",
            "layerType": "Training",
            "layerSettings": {
                "Labels": "1596824119748",
                "Epochs": "10",
                "N_class": "1",
                "Loss": "Cross_entropy",
                "Class_weights": "1",
                "Learning_rate": "0.001",
                "Optimizer": "ADAM",
                "Beta_1": "0.9",
                "Beta_2": "0.999",
                "Momentum": "0.9",
                "Decay_steps": "100000",
                "Decay_rate": "0.96",
                "Training_iters": "20000",
                "Batch_size": "256"
            },
            "layerSettingsTabName": "Code",
            "layerCode": {
                "Output": "class TrainNormal_Normal_1(ClassificationLayer):\n\n    def __init__(self):\n        self._n_epochs = 10\n        self._batch_size = 256\n\n        self._stopped = False\n        self._paused = False\n        self._headless = False\n        self._status = 'created'\n        \n        self._loss_training = 0.0\n        self._loss_validation = 0.0\n        self._loss_testing = 0.0      \n\n        self._accuracy_training = 0.0\n        self._accuracy_validation = 0.0\n        self._accuracy_testing = 0.0      \n        \n        self._variables = {}\n        self._layer_outputs = {}\n        self._layer_weights = {}\n        self._layer_biases = {}        \n        self._layer_gradients = {}\n\n        self._training_iteration = 0\n        self._validation_iteration = 0\n        self._testing_iteration = 0\n\n        self._trn_sz_tot = 0\n        self._val_sz_tot = 0\n        self._tst_sz_tot = 0\n\n        self._checkpoint = None\n        \n    def run(self, graph: Graph):\n        \"\"\"Called as the main entry point for training. Responsible for training the model.\n\n        Args:\n            graph: A PerceptiLabs Graph object containing references to all layers objects included in the model produced by this training layer.\n        \"\"\"   \n        self._status = 'initializing'\n        output_layer_id = '_Fully_Connected_1'\n        target_layer_id = '_OneHot_1'\n        input_data_nodes = graph.get_direct_data_nodes(output_layer_id)\n        label_data_nodes = graph.get_direct_data_nodes(target_layer_id)\n\n        assert len(input_data_nodes) == 1\n        assert len(label_data_nodes) == 1\n        input_data_node = input_data_nodes[0]\n        label_data_node = label_data_nodes[0]\n        \n        self._trn_sz_tot = input_data_node.layer.size_training\n        self._val_sz_tot = input_data_node.layer.size_validation\n        self._tst_sz_tot = input_data_node.layer.size_testing\n\n        # Make training set\n        dataset_trn = tf.data.Dataset.zip((\n            tf.data.Dataset.from_generator(\n                input_data_node.layer_instance.make_generator_training,\n                output_shapes=input_data_node.layer_instance.sample.shape,\n                output_types=np.float32                \n            ),\n            tf.data.Dataset.from_generator(\n                label_data_node.layer_instance.make_generator_training,\n                output_shapes=label_data_node.layer_instance.sample.shape,\n                output_types=np.float32\n            )\n        ))\n\n        # Make validation set\n        dataset_val = tf.data.Dataset.zip((\n            tf.data.Dataset.from_generator(\n                input_data_node.layer_instance.make_generator_validation,\n                output_shapes=input_data_node.layer_instance.sample.shape,\n                output_types=np.float32                \n            ),\n            tf.data.Dataset.from_generator(\n                label_data_node.layer_instance.make_generator_validation,\n                output_shapes=label_data_node.layer_instance.sample.shape,\n                output_types=np.float32\n            )\n        ))\n\n        # Make testing set\n        dataset_tst = tf.data.Dataset.zip((\n            tf.data.Dataset.from_generator(\n                input_data_node.layer_instance.make_generator_testing,\n                output_shapes=input_data_node.layer_instance.sample.shape,\n                output_types=np.float32                \n            ),\n            tf.data.Dataset.from_generator(\n                label_data_node.layer_instance.make_generator_testing,\n                output_shapes=label_data_node.layer_instance.sample.shape,\n                output_types=np.float32\n            )\n        ))\n        \n        dataset_trn = dataset_trn.batch(self._batch_size, drop_remainder=True)\n        dataset_val = dataset_val.batch(self._batch_size, drop_remainder=True)\n        dataset_tst = dataset_tst.batch(1)                \n\n        # Make initializers\n        with tf.variable_scope('TrainNormal_Normal_1/train', reuse=tf.AUTO_REUSE):\n            is_training = tf.get_variable(name=\"is_train\", dtype=tf.bool, initializer=False)\n\n        iterator = tf.data.Iterator.from_structure(dataset_trn.output_types, dataset_trn.output_shapes)\n\n        trn_init = iterator.make_initializer(dataset_trn)\n        trn_init = tf.group([trn_init, is_training.assign(True if self._batch_size > 1 else False)])\n        \n        val_init = iterator.make_initializer(dataset_val)\n        val_init = tf.group([val_init, is_training.assign(False)])\n\n        tst_init = iterator.make_initializer(dataset_tst)        \n        tst_init = tf.group([tst_init, is_training.assign(False)])\n\n        input_tensor, label_tensor = iterator.get_next()\n\n        # Build the TensorFlow graph # TODO: perhaps this part can be delegated to the graph?\n\n        def build_graph(input_tensor, label_tensor):\n            layer_output_tensors = {\n                input_data_node.layer_id: input_tensor,\n                label_data_node.layer_id: label_tensor\n            }\n\n            for node in graph.inner_nodes:\n                args = []\n                for input_node in graph.get_input_nodes(node):\n                    args.append(layer_output_tensors[input_node.layer_id])\n\n                y = node.layer_instance(*args)\n                layer_output_tensors[node.layer_id] = y\n\n\n            return layer_output_tensors\n\n        layer_output_tensors = build_graph(input_tensor, label_tensor)\n        output_tensor = layer_output_tensors[output_layer_id]\n        target_tensor = layer_output_tensors[target_layer_id]\n        \n        update_ops = tf.compat.v1.get_collection(tf.GraphKeys.UPDATE_OPS)\n        \n        # Create an exportable version of the TensorFlow graph\n        self._input_tensor_export = tf.placeholder(shape=dataset_trn.output_shapes[0], dtype=dataset_trn.output_types[0])\n        self._output_tensor_export = build_graph(\n            self._input_tensor_export,\n            tf.placeholder(shape=dataset_trn.output_shapes[1], dtype=dataset_trn.output_types[1])\n        )[output_layer_id]\n        \n        # Defining loss function\n        n_classes = output_tensor.get_shape().as_list()[-1]\n        flat_pred = tf.reshape(output_tensor, [-1, n_classes])\n        flat_labels = tf.reshape(target_tensor, [-1, n_classes])\n        loss_tensor = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=flat_labels, logits=flat_pred))\n\n        correct_predictions = tf.equal(tf.argmax(output_tensor, -1), tf.argmax(target_tensor, -1))\n        accuracy_tensor = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n\n        global_step = None\n\n        optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)\n\n        layer_weight_tensors = {}\n        layer_bias_tensors = {}        \n        layer_gradient_tensors = {}\n        for node in graph.inner_nodes:\n            if not isinstance(node.layer, Tf1xLayer): # In case of pure custom layers...\n                continue\n            \n            layer_weight_tensors[node.layer_id] = node.layer.weights\n            layer_bias_tensors[node.layer_id] = node.layer.biases            \n            \n            if len(node.layer.trainable_variables) > 0:\n                gradients = {}\n                for name, tensor in node.layer.trainable_variables.items():\n                    grad_tensor = tf.gradients(loss_tensor, tensor)\n                    if any(x is None for x in grad_tensor):\n                        grad_tensor = tf.constant(0)\n                    gradients[name] = grad_tensor\n                layer_gradient_tensors[node.layer_id] = gradients\n                # self._internal_layer_gradients[node.layer_id] = {name: [] for name in node.layer.trainable_variables.keys()} # Initialize\n                # self._layer_gradients = self._internal_layer_gradients.copy()\n\n        # trainable_vars = tf.trainable_variables() # TODO: safer to get from nodes. Especially with split graph in mind.\n        # grads = tf.gradients(loss_tensor, trainable_vars)\n        # update_weights = optimizer.apply_gradients(zip(grads, trainable_vars), global_step=global_step)        \n        \n        update_weights = optimizer.minimize(loss_tensor, global_step=global_step)\n        update_weights = tf.group([update_weights, update_ops])\n\n        sess = None\n         \n        config = tf.ConfigProto(device_count={\"GPU\": 0})\n        sess = tf.Session(config=config)\n        \n        self._sess = sess\n        \n\n        trackable_variables = {}\n        trackable_variables.update({x.name: x for x in tf.trainable_variables() if isinstance(x, Trackable)})\n        trackable_variables.update({k: v for k, v in locals().items() if isinstance(v, Trackable) and not isinstance(v, tf.python.data.ops.iterator_ops.Iterator)}) # TODO: Iterators based on 'stateful functions' cannot be serialized.\n        self._checkpoint = tf.train.Checkpoint(**trackable_variables)\n\n        sess.run(tf.global_variables_initializer())\n        \n                    \n\n        def train_step():\n            if not self._headless:\n                _, self._loss_training, self._accuracy_training, \\\n                    self._layer_outputs, self._layer_weights, self._layer_biases, \\\n                    self._layer_gradients \\\n                    = sess.run([\n                        update_weights, loss_tensor, accuracy_tensor,\n                        layer_output_tensors, layer_weight_tensors, layer_bias_tensors, layer_gradient_tensors\n                    ])\n            else:\n                _, self._loss_training, self._accuracy_training, \\\n                    = sess.run([\n                        update_weights, loss_tensor, accuracy_tensor\n                    ])\n            \n        def validation_step():\n            if not self._headless:\n                self._loss_validation, self._accuracy_validation, \\\n                    self._layer_outputs, self._layer_weights, self._layer_biases, \\\n                    self._layer_gradients \\\n                    = sess.run([\n                        loss_tensor, accuracy_tensor,\n                        layer_output_tensors, layer_weight_tensors, layer_bias_tensors, layer_gradient_tensors\n                    ])\n            else:\n                self._loss_validation, self._accuracy_validation, \\\n                    = sess.run([\n                        loss_tensor, accuracy_tensor\n                    ])\n\n            \n        def test_step():\n            self._loss_testing, self._accuracy_testing, \\\n                self._layer_outputs, self._layer_weights, self._layer_gradients \\\n                = sess.run([\n                    loss_tensor, accuracy_tensor,\n                    layer_output_tensors, layer_weight_tensors, layer_gradient_tensors\n                ])\n            #accuracy_list.append(acc)\n            #loss_list.append(loss)\n\n        self._variables = {k: v for k, v in locals().items() if can_serialize(v)}\n\n        log.info(\"Entering training loop\")\n\n        # Training loop\n        self._epoch = 0\n        while self._epoch < self._n_epochs and not self._stopped:\n            t0 = time.perf_counter()\n            self._training_iteration = 0\n            self._validation_iteration = 0\n            self._status = 'training'\n            sess.run(trn_init)            \n            try:\n                while not self._stopped:\n                    train_step()\n                    yield YieldLevel.SNAPSHOT\n                    self._training_iteration += 1\n            except tf.errors.OutOfRangeError:\n                pass\n\n            self._status = 'validation'\n            sess.run(val_init)            \n            try:\n                while not self._stopped:\n                    validation_step()\n                    yield YieldLevel.SNAPSHOT                    \n                    self._validation_iteration += 1\n            except tf.errors.OutOfRangeError:\n                pass\n            log.info(\n                f\"Finished epoch {self._epoch+1}/{self._n_epochs} - \"\n                f\"loss training, validation: {self.loss_training:.6f}, {self.loss_validation:.6f} - \"\n                f\"acc. training, validation: {self.accuracy_training:.6f}, {self.accuracy_validation:.6f}\"\n            )\n            log.info(f\"Epoch duration: {round(time.perf_counter() - t0, 3)} s\")            \n            self._epoch += 1\n\n        self._variables = {k: v for k, v in locals().items() if can_serialize(v)}            \n        yield YieldLevel.DEFAULT            \n        \n        # Test loop\n        self._testing_iteration = 0\n        self._status = 'testing'\n        sess.run(tst_init)                                \n        try:\n            while not self._stopped:\n                test_step()\n                yield YieldLevel.SNAPSHOT\n                self._testing_iteration += 1\n        except tf.errors.OutOfRangeError:\n            pass\n\n        self._status = 'finished'\n        self._variables = {k: v for k, v in locals().items() if can_serialize(v)}\n        yield YieldLevel.DEFAULT\n\n                \n\n    def on_export(self, path: str, mode: str) -> None:\n        \"\"\"Called when the export or save button is clicked in the frontend.\n        It is up to the implementing layer to save the model to disk.\n        \n        Args:\n            path: the directory where the exported model will be stored.\n            mode: how to export the model. Made available to frontend via 'export_modes' property.\"\"\"\n\n        log.debug(f\"Export called. Project path = {path}, mode = {mode}\")\n        pb_path = os.path.join(path, '1')\n\n        if os.path.exists(pb_path):\n            shutil.rmtree(pb_path)\n\n        os.makedirs(pb_path, exist_ok=True)\n        \n        # Export non-compressed model\n        if mode in ['TFModel', 'TFModel+checkpoint']:\n            tf.compat.v1.saved_model.simple_save(self._sess, pb_path, inputs={'input': self._input_tensor_export}, outputs={'output': self._output_tensor_export})\n\n        # Export compressed model\n        if mode in ['TFLite', 'TFLite+checkpoint']:\n            frozen_path = os.path.join(pb_path, 'frozen_model.pb')\n            converter = tf.lite.TFLiteConverter.from_session(self._sess, [self._input_tensor_export], [self._output_tensor_export])\n            converter.post_training_quantize = True\n            tflite_model = converter.convert()\n            with open(frozen_path, \"wb\") as f:\n                f.write(tflite_model)\n\n        # Export checkpoint\n        if mode in ['TFModel+checkpoint', 'TFLite+checkpoint']:\n            self._checkpoint.save(file_prefix=os.path.join(path, 'model.ckpt'), session=self._sess)\n                \n    def on_stop(self) -> None:\n        \"\"\"Called when the save model button is clicked in the frontend. \n        It is up to the implementing layer to save the model to disk.\"\"\"\n        self._stopped = True\n\n    def on_headless_activate(self) -> None:\n        \"\"\"\"Called when the statistics shown in statistics window are not needed.\n        Purose is to speed up the iteration speed significantly.\"\"\"\n        self._headless = True\n\n        self._layer_outputs = {} \n        self._layer_weights = {}\n        self._layer_biases = {}\n        self._layer_gradients = {}\n\n    def on_headless_deactivate(self) -> None:\n        \"\"\"\"Called when the statistics shown in statistics window are needed.\n        May slow down the iteration speed of the training.\"\"\"\n        import time\n        log.info(f\"Set to headless_off at time {time.time()}\")\n        self._headless = False\n\n    @property\n    def export_modes(self) -> List[str]:\n        \"\"\"Returns the possible modes of exporting a model.\"\"\"        \n        return [\n            'TFModel',\n            'TFLite'\n            'TFModel+checkpoint',\n            'TFLite+checkpoint',            \n        ]\n        \n    @property\n    def is_paused(self) -> None:\n        \"\"\"Returns true when the training is paused.\"\"\"        \n        return self._paused\n\n    @property\n    def batch_size(self):\n        \"\"\" Size of the current training batch \"\"\"        \n        return self._batch_size\n\n    @property\n    def status(self):\n        \"\"\"Called when the pause button is clicked in the frontend. It is up to the implementing layer to pause its execution.\"\"\"        \n        return self._status\n    \n    @property\n    def epoch(self):\n        \"\"\"The current epoch\"\"\"        \n        return self._epoch\n\n    @property\n    def variables(self):\n        \"\"\"Any variables belonging to this layer that should be rendered in the frontend.\n        \n        Returns:\n            A dictionary with tensor names for keys and picklable for values.\n        \"\"\"\n        return self._variables.copy()        \n\n    @property\n    def sample(self) -> np.ndarray:\n        \"\"\"Returns a single data sample\"\"\"        \n        return np.empty(())\n\n    @property\n    def columns(self) -> List[str]: \n        \"\"\"Column names. Corresponds to each column in a sample \"\"\"\n        return []\n\n    @property\n    def size_training(self) -> int:\n        \"\"\"Returns the size of the training dataset\"\"\"                                    \n        return self._trn_sz_tot\n\n    @property\n    def size_validation(self) -> int:\n        \"\"\"Returns the size of the validation dataset\"\"\"                                            \n        return self._val_sz_tot\n\n    @property\n    def size_testing(self) -> int:\n        \"\"\"Returns the size of the testing dataset\"\"\"\n        return self._tst_sz_tot\n\n    def make_generator_training(self) -> Generator[np.ndarray, None, None]:\n        \"\"\"Returns a generator yielding single samples of training data. In the case of a training layer, this typically yields the model output.\"\"\"        \n        # Simply call sess.run on the output & target tensors :)  #TODO: how to make generators generic? We have two datasets here, but not all datasets will be labeled. Distinguish between supervised/unsupervised data layers and instead REQUIRE pairs of data layers for supervised?\n        yield from []\n        \n    def make_generator_validation(self) -> Generator[np.ndarray, None, None]:\n        \"\"\"Returns a generator yielding single samples of validation data. In the case of a training layer, this typically yields the model output.\"\"\"                \n        yield from []\n        \n    def make_generator_testing(self) -> Generator[np.ndarray, None, None]:\n        \"\"\"Returns a generator yielding single samples of testing data. In the case of a training layer, this typically yields the model output.\"\"\"                        \n        yield from []\n\n    @property\n    def accuracy_training(self) -> float:\n        \"\"\"Returns the current accuracy of the training phase\"\"\"        \n        return self._accuracy_training\n    \n    @property\n    def accuracy_validation(self) -> float:\n        \"\"\"Returns the current accuracy of the validation phase\"\"\"                \n        return self._accuracy_validation\n\n    @property\n    def accuracy_testing(self) -> float:\n        \"\"\"Returns the current accuracy of the testing phase\"\"\"                        \n        return self._accuracy_testing\n\n    @property\n    def loss_training(self) -> float:\n        \"\"\"Returns the current loss of the training phase\"\"\"                \n        return self._loss_training        \n\n    @property\n    def loss_validation(self) -> float:\n        \"\"\"Returns the current loss of the validation phase\"\"\"                        \n        return self._loss_validation        \n\n    @property\n    def loss_testing(self) -> float:\n        \"\"\"Returns the current loss of the testing phase\"\"\"                \n        return self._loss_testing\n\n    @property\n    def layer_weights(self) -> Dict[str, Dict[str, Picklable]]:\n        \"\"\"The weight values of each layer in the input Graph during the training.\n\n        Returns:\n            A dictionary of nested dictionaries, where each key is a layer id. The nested dictionaries contain weight name and value pairs. The values must be picklable.\n        \"\"\"        \n        return self._layer_weights\n\n    @property\n    def layer_biases(self) -> Dict[str, Dict[str, Picklable]]:\n        \"\"\"The bias values of each layer in the input Graph during the training.\n\n        Returns:\n            A dictionary of nested dictionaries, where each key is a layer id. The nested dictionaries contain weight name and value pairs. The values must be picklable.\n        \"\"\"        \n        return self._layer_biases\n    \n    @property\n    def layer_gradients(self) -> Dict[str, Dict[str, Picklable]]:\n        \"\"\"The gradients with respect to the loss of all trainable variables of each layer in the input Graph.\n\n        Returns:\n            A dictionary of nested dictionaries, where each key is a layer id. The nested dictionaries contain gradient name and value pairs. The values must be picklable.\n        \"\"\"        \n        return self._layer_gradients\n    \n    @property\n    def layer_outputs(self) -> Dict[str, Dict[str, Picklable]]:\n        \"\"\"The output values of each layer in the input Graph during the training (e.g., tf.Tensors evaluated for each iteration)\n\n        Returns:\n            A dictionary of nested dictionaries, where each key is a layer id. The nested dictionaries contain variable name and value pairs. The values must be picklable.\n        \"\"\"\n        return self._layer_outputs\n\n    @property\n    def training_iteration(self) -> int:\n        \"\"\"The current training iteration\"\"\"\n        return self._training_iteration\n\n    @property\n    def validation_iteration(self) -> int:\n        \"\"\"The current validation iteration\"\"\"        \n        return self._validation_iteration\n\n    @property\n    def testing_iteration(self) -> int:\n        \"\"\"The current testing iteration\"\"\"                \n        return self._testing_iteration\n    \n    @property\n    def progress(self) -> float:\n        \"\"\"A number indicating the overall progress of the training\n        \n        Returns:\n            A floating point number between 0 and 1\n        \"\"\"        \n        n_iterations_per_epoch = np.ceil(self.size_training / self.batch_size) + \\\n                                 np.ceil(self.size_validation / self.batch_size)\n        n_iterations_total = self._n_epochs * n_iterations_per_epoch\n\n        iteration = self.epoch * n_iterations_per_epoch + \\\n                    self.training_iteration + self.validation_iteration\n        \n        progress = min(iteration/(n_iterations_total - 1), 1.0) \n        return progress\n"
            },
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": true,
                "position": {
                    "top": 340,
                    "left": 970
                },
                "OutputDim": "",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "TrainNormal",
            "connectionOut": [],
            "connectionIn": [
                "1596824119748",
                "1596824298894"
            ],
            "connectionArrow": []
        },
        "1596825463589": {
            "layerId": "1596825463589",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_5",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "1",
                "Padding": "SAME",
                "Feature_maps": "64",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 250,
                    "left": 310
                },
                "OutputDim": "32x32x64",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596825483525"
            ],
            "connectionIn": [
                "1596824132180"
            ],
            "connectionArrow": [
                "1596825483525"
            ]
        },
        "1596825483525": {
            "layerId": "1596825483525",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Merge_1",
            "layerType": "Other",
            "layerSettings": {
                "Type": "Add",
                "Merge_dim": ""
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 204.5,
                    "left": 400.5
                },
                "OutputDim": "32x32x64",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "MathMerge",
            "connectionOut": [
                "1596824172196"
            ],
            "connectionIn": [
                "1596825463589",
                "1596824132180"
            ],
            "connectionArrow": [
                "1596824172196"
            ]
        },
        "1596825573649": {
            "layerId": "1596825573649",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_6",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "1",
                "Padding": "SAME",
                "Feature_maps": "128",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 250,
                    "left": 490
                },
                "OutputDim": "16x16x128",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596825586247"
            ],
            "connectionIn": [
                "1596824172196"
            ],
            "connectionArrow": [
                "1596825586247"
            ]
        },
        "1596825586247": {
            "layerId": "1596825586247",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Merge_2",
            "layerType": "Other",
            "layerSettings": {
                "Type": "Add",
                "Merge_dim": ""
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 200,
                    "left": 580
                },
                "OutputDim": "16x16x128",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "MathMerge",
            "connectionOut": [
                "1596824199078"
            ],
            "connectionIn": [
                "1596825573649",
                "1596824172196"
            ],
            "connectionArrow": [
                "1596824199078"
            ]
        },
        "1596825603293": {
            "layerId": "1596825603293",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_7",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "1",
                "Padding": "SAME",
                "Feature_maps": "256",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 240,
                    "left": 680
                },
                "OutputDim": "8x8x256",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596825646014"
            ],
            "connectionIn": [
                "1596824199078"
            ],
            "connectionArrow": [
                "1596825646014"
            ]
        },
        "1596825646014": {
            "layerId": "1596825646014",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Merge_3",
            "layerType": "Other",
            "layerSettings": {
                "Type": "Add",
                "Merge_dim": ""
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 200,
                    "left": 770
                },
                "OutputDim": "8x8x256",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "MathMerge",
            "connectionOut": [
                "1596825658495"
            ],
            "connectionIn": [
                "1596825603293",
                "1596824199078"
            ],
            "connectionArrow": [
                "1596825658495"
            ]
        },
        "1596825658495": {
            "layerId": "1596825658495",
            "copyId": null,
            "copyContainerElement": null,
            "layerName": "Convolution_4",
            "layerType": "Other",
            "layerSettings": {
                "Conv_dim": "2D",
                "Patch_size": "3",
                "Stride": "9",
                "Padding": "SAME",
                "Feature_maps": "512",
                "Activation_function": "LeakyReLU",
                "Dropout": false,
                "Keep_prob": "1",
                "Batch_norm": true,
                "PoolBool": false,
                "Pooling": "Max",
                "Pool_area": "2",
                "Pool_padding": "SAME",
                "Pool_stride": "2"
            },
            "layerSettingsTabName": "Settings",
            "layerCode": null,
            "layerCodeError": null,
            "layerNone": false,
            "layerMeta": {
                "isInvisible": false,
                "isLock": false,
                "isSelected": false,
                "position": {
                    "top": 200,
                    "left": 860
                },
                "OutputDim": "1x1x512",
                "InputDim": "",
                "layerContainerName": "",
                "layerBgColor": "",
                "containerDiff": {
                    "top": 0,
                    "left": 0
                }
            },
            "checkpoint": [],
            "endPoints": [],
            "componentName": "DeepLearningConv",
            "connectionOut": [
                "1596824298894"
            ],
            "connectionIn": [
                "1596825646014"
            ],
            "connectionArrow": [
                "1596824298894"
            ]
        }
    },
    "apiMeta": {
        "name": "Textile-Classification",
        "created": "2020-08-07T18:14:42.634006Z",
        "updated": "2020-08-07T18:14:42.634047Z",
        "location": ""
    }
}